{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Previsão de receita por pessoa com base no Censo</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste notebook contém um projeto desenvolvido durante o curso \"Machine Learning e Data Science com Python de A a Z\" da instituição Udemy.\n",
    "\n",
    "OBJETIVO DA ANÁLISE:\n",
    "- Comparar algoritmos de Machine Learning que possam prever se a receita ultrapassa 50 mil/ano com base nos dados do censo. \n",
    "  Também conhecido como conjunto de dados \"Census Income\".\n",
    "  - > 50K, <= 50K.\n",
    "  \n",
    "Informações do conjunto de dados:\n",
    "- Data set pode ser encontrado no link: http://archive.ics.uci.edu/ml/datasets/Adult\n",
    "- A extração foi feita por Barry Becker do banco de dados do Censo de 1994.\n",
    "- A tarefa de previsão é determinar se uma pessoa ganha mais de 50K por ano.\n",
    "\n",
    "Algoritmos de Classificação utilizados:\n",
    "- Naive Bayes\n",
    "- Árvore de Decisão\n",
    "- Random Forest\n",
    "- KNN\n",
    "- Regressão Logística\n",
    "- SVM\n",
    "- Redes Neurais Artificiais\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Importando a base de dados</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importando a base de dados\n",
    "# para uma melhor compreensão, será alterado o nome das colunas\n",
    "base = pd.read_csv('census.csv', names = ['idade', 'tipo_emprego', 'caracteristica', 'educacao', 'anos_estudo', \\\n",
    "                                        'estado_civil', 'ocupacao', 'parentesco', 'raça', 'sexo', 'ganho_capital', \\\n",
    "                                        'perda_capital','hrs_trabalhada_semana', 'pais_origem', 'renda_anual'], header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idade</th>\n",
       "      <th>tipo_emprego</th>\n",
       "      <th>caracteristica</th>\n",
       "      <th>educacao</th>\n",
       "      <th>anos_estudo</th>\n",
       "      <th>estado_civil</th>\n",
       "      <th>ocupacao</th>\n",
       "      <th>parentesco</th>\n",
       "      <th>raça</th>\n",
       "      <th>sexo</th>\n",
       "      <th>ganho_capital</th>\n",
       "      <th>perda_capital</th>\n",
       "      <th>hrs_trabalhada_semana</th>\n",
       "      <th>pais_origem</th>\n",
       "      <th>renda_anual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>160187</td>\n",
       "      <td>9th</td>\n",
       "      <td>5</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Jamaica</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>209642</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>45781</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>14084</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42</td>\n",
       "      <td>Private</td>\n",
       "      <td>159449</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>5178</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idade       tipo_emprego  caracteristica    educacao  anos_estudo  \\\n",
       "0     39          State-gov           77516   Bachelors           13   \n",
       "1     50   Self-emp-not-inc           83311   Bachelors           13   \n",
       "2     38            Private          215646     HS-grad            9   \n",
       "3     53            Private          234721        11th            7   \n",
       "4     28            Private          338409   Bachelors           13   \n",
       "5     37            Private          284582     Masters           14   \n",
       "6     49            Private          160187         9th            5   \n",
       "7     52   Self-emp-not-inc          209642     HS-grad            9   \n",
       "8     31            Private           45781     Masters           14   \n",
       "9     42            Private          159449   Bachelors           13   \n",
       "\n",
       "             estado_civil            ocupacao      parentesco    raça  \\\n",
       "0           Never-married        Adm-clerical   Not-in-family   White   \n",
       "1      Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "2                Divorced   Handlers-cleaners   Not-in-family   White   \n",
       "3      Married-civ-spouse   Handlers-cleaners         Husband   Black   \n",
       "4      Married-civ-spouse      Prof-specialty            Wife   Black   \n",
       "5      Married-civ-spouse     Exec-managerial            Wife   White   \n",
       "6   Married-spouse-absent       Other-service   Not-in-family   Black   \n",
       "7      Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "8           Never-married      Prof-specialty   Not-in-family   White   \n",
       "9      Married-civ-spouse     Exec-managerial         Husband   White   \n",
       "\n",
       "      sexo  ganho_capital  perda_capital  hrs_trabalhada_semana  \\\n",
       "0     Male           2174              0                     40   \n",
       "1     Male              0              0                     13   \n",
       "2     Male              0              0                     40   \n",
       "3     Male              0              0                     40   \n",
       "4   Female              0              0                     40   \n",
       "5   Female              0              0                     40   \n",
       "6   Female              0              0                     16   \n",
       "7     Male              0              0                     45   \n",
       "8   Female          14084              0                     50   \n",
       "9     Male           5178              0                     40   \n",
       "\n",
       "      pais_origem renda_anual  \n",
       "0   United-States       <=50K  \n",
       "1   United-States       <=50K  \n",
       "2   United-States       <=50K  \n",
       "3   United-States       <=50K  \n",
       "4            Cuba       <=50K  \n",
       "5   United-States       <=50K  \n",
       "6         Jamaica       <=50K  \n",
       "7   United-States        >50K  \n",
       "8   United-States        >50K  \n",
       "9   United-States        >50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Explorando os dados</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idade                     int64\n",
       "tipo_emprego             object\n",
       "caracteristica            int64\n",
       "educacao                 object\n",
       "anos_estudo               int64\n",
       "estado_civil             object\n",
       "ocupacao                 object\n",
       "parentesco               object\n",
       "raça                     object\n",
       "sexo                     object\n",
       "ganho_capital             int64\n",
       "perda_capital             int64\n",
       "hrs_trabalhada_semana     int64\n",
       "pais_origem              object\n",
       "renda_anual              object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificando o tipo de dados de cada coluna\n",
    "base.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O dataset tem 32561 linhas e 15 colunas\n"
     ]
    }
   ],
   "source": [
    "# quantidade de linhas e colunas do dataFrame\n",
    "base.shape\n",
    "print(\"O dataset tem {} linhas e {} colunas\".format(base.shape[0], base.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 32561 entries, 0 to 32560\n",
      "Data columns (total 15 columns):\n",
      " #   Column                 Non-Null Count  Dtype \n",
      "---  ------                 --------------  ----- \n",
      " 0   idade                  32561 non-null  int64 \n",
      " 1   tipo_emprego           32561 non-null  object\n",
      " 2   caracteristica         32561 non-null  int64 \n",
      " 3   educacao               32561 non-null  object\n",
      " 4   anos_estudo            32561 non-null  int64 \n",
      " 5   estado_civil           32561 non-null  object\n",
      " 6   ocupacao               32561 non-null  object\n",
      " 7   parentesco             32561 non-null  object\n",
      " 8   raça                   32561 non-null  object\n",
      " 9   sexo                   32561 non-null  object\n",
      " 10  ganho_capital          32561 non-null  int64 \n",
      " 11  perda_capital          32561 non-null  int64 \n",
      " 12  hrs_trabalhada_semana  32561 non-null  int64 \n",
      " 13  pais_origem            32561 non-null  object\n",
      " 14  renda_anual            32561 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# utilizando a função Info para obter um resumo sobre o dataset \n",
    "base.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Atributos previsores e classe</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando uma variável para armazenar os atributos previsores\n",
    "previsores = base.iloc[:, 0:14].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39, ' State-gov', 77516, ..., 0, 40, ' United-States'],\n",
       "       [50, ' Self-emp-not-inc', 83311, ..., 0, 13, ' United-States'],\n",
       "       [38, ' Private', 215646, ..., 0, 40, ' United-States'],\n",
       "       ...,\n",
       "       [58, ' Private', 151910, ..., 0, 40, ' United-States'],\n",
       "       [22, ' Private', 201490, ..., 0, 20, ' United-States'],\n",
       "       [52, ' Self-emp-inc', 287927, ..., 0, 40, ' United-States']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criando uma variável para armazenar o atributo classe\n",
    "classe = base.iloc[:, 14].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' <=50K', ' <=50K', ' <=50K', ..., ' <=50K', ' <=50K', ' >50K'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Transformação de variáveis categóricas</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoder para transformar as variáveis categóricas em numéricas\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformando as variáveis categóricas dos atributos previsores\n",
    "labelencoder_previsores = LabelEncoder()\n",
    "\n",
    "previsores[:, 1] = labelencoder_previsores.fit_transform(previsores[:, 1])\n",
    "previsores[:, 3] = labelencoder_previsores.fit_transform(previsores[:, 3])\n",
    "previsores[:, 5] = labelencoder_previsores.fit_transform(previsores[:, 5])\n",
    "previsores[:, 6] = labelencoder_previsores.fit_transform(previsores[:, 6])\n",
    "previsores[:, 7] = labelencoder_previsores.fit_transform(previsores[:, 7])\n",
    "previsores[:, 8] = labelencoder_previsores.fit_transform(previsores[:, 8])\n",
    "previsores[:, 9] = labelencoder_previsores.fit_transform(previsores[:, 9])\n",
    "previsores[:, 13] = labelencoder_previsores.fit_transform(previsores[:, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39, 7, 77516, ..., 0, 40, 39],\n",
       "       [50, 6, 83311, ..., 0, 13, 39],\n",
       "       [38, 4, 215646, ..., 0, 40, 39],\n",
       "       ...,\n",
       "       [58, 4, 151910, ..., 0, 40, 39],\n",
       "       [22, 4, 201490, ..., 0, 20, 39],\n",
       "       [52, 5, 287927, ..., 0, 40, 39]], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformando a variável categórica do atributo classe\n",
    "labelencoder_classe = LabelEncoder()\n",
    "classe = labelencoder_classe.fit_transform(classe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# <= 50K tem o valor = 0\n",
    "# > 50K tem o valor = 1\n",
    "classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Escalonamento dos atributos</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar uma fórmula para os atributos na mesma escala\n",
    "# Utilizando a Padronização x= x - média(x) / desvioPadrão(x)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "previsores = scaler.fit_transform(previsores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03067056,  2.15057856, -1.06361075, ..., -0.21665953,\n",
       "        -0.03542945,  0.29156857],\n",
       "       [ 0.83710898,  1.46373585, -1.008707  , ..., -0.21665953,\n",
       "        -2.22215312,  0.29156857],\n",
       "       [-0.04264203,  0.09005041,  0.2450785 , ..., -0.21665953,\n",
       "        -0.03542945,  0.29156857],\n",
       "       ...,\n",
       "       [ 1.42360965,  0.09005041, -0.35877741, ..., -0.21665953,\n",
       "        -0.03542945,  0.29156857],\n",
       "       [-1.21564337,  0.09005041,  0.11095988, ..., -0.21665953,\n",
       "        -1.65522476,  0.29156857],\n",
       "       [ 0.98373415,  0.77689313,  0.92989258, ..., -0.21665953,\n",
       "        -0.03542945,  0.29156857]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Spliting</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividindo as variáveis em treino e teste\n",
    "# 85% dados para treino e 15% dados para teste\n",
    "from sklearn.model_selection import train_test_split\n",
    "previsores_treinamento, previsores_teste, classe_treinamento, classe_teste = train_test_split(previsores, classe, \\\n",
    "                                                                                             test_size=0.15, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.00% nos dados de treino\n",
      "15.00% nos dados de teste\n"
     ]
    }
   ],
   "source": [
    "# Imprimindo os resultados\n",
    "print(\"{0:0.2f}% nos dados de treino\".format((len(previsores_treinamento)/len(base.index)) * 100))\n",
    "print(\"{0:0.2f}% nos dados de teste\".format((len(previsores_teste)/len(base.index)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27676"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(previsores_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27676"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classe_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4885"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(previsores_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4885"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(classe_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Naive Bayes</h1>\n",
    "\n",
    "O algoritmo “Naive Bayes” é um classificador probabilístico.\n",
    "Ele recebe o nome de “naive” (ingênuo) porque desconsidera a correlação entre as variáveis (features).\n",
    "\n",
    "Classificação de textos, filtragem de SPAM e análise de sentimento em redes sociais são algumas das muitas aplicações para esse algoritmo.\n",
    "O algoritmo é muito robusto para previsões em tempo real, pois precisa de poucos dados para realizar a classificação. Se existe a necessidade de correlacionar fatores, esse algoritmo tende a falhar nas predições."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo e treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o algoritmo\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo preditivo\n",
    "classificador = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinando o modelo\n",
    "classificador.fit(previsores_treinamento, classe_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testando o modelo\n",
    "previsoes = classificador.predict(previsores_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando a exatidão no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8057318321392016"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precisão do modelo\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "precisao = accuracy_score(classe_teste, previsoes)\n",
    "precisao "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3528,  165],\n",
       "       [ 784,  408]], dtype=int64)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão\n",
    "# diagonal principal (quantidade de acertos)\n",
    "matriz = confusion_matrix(classe_teste, previsoes)\n",
    "matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Árvore de Decisão</h1>\n",
    "\n",
    "Uma árvore de decisão utiliza base de dados histórica e geralmente começa com um único nó, que se divide em possíveis resultados. Cada um desses resultados leva a nós adicionais, que se ramificam em outras possibilidades. Assim, cria-se uma forma de árvore. Esses algoritmos são considerados um dos melhores e mais utilizados métodos de aprendizagem supervisionada, pois nos dão modelos preditivos de alta precisão, estabilidade e facilidade de interpretação. Ao contrário dos modelos lineares, eles mapeiam muito bem relações não-lineares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo e treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o algoritmo\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo preditivo\n",
    "classificador = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinando o modelo\n",
    "classificador.fit(previsores_treinamento, classe_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testando o modelo\n",
    "previsoes = classificador.predict(previsores_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando a exatidão no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8128966223132037"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precisão do modelo\n",
    "precisao = accuracy_score(classe_teste, previsoes)\n",
    "precisao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3239,  454],\n",
       "       [ 460,  732]], dtype=int64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão\n",
    "# diagonal principal (quantidade de acertos)\n",
    "matriz = confusion_matrix(classe_teste, previsoes)\n",
    "matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Random Forest</h1>\n",
    "\n",
    "Esse algoritmo irá criar muitas árvores de decisão, de maneira aleatória, formando o que podemos enxergar como uma floresta, onde cada árvore será utilizada na escolha do resultado final. É um método de aprendizagem de máquina versátil e capaz de executar tarefas de regressão e de classificação. Ele também aplica métodos de redução dimensional, trata valores faltantes, valores anómalos (‘outliers’) e outras etapas essenciais da exploração de dados.\n",
    "É um tipo de método de aprendizado de ‘ensemble’, onde um grupo de modelos fracos são combinados para formar um modelo mais forte."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo e treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o algoritmo\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo preditivo\n",
    "classificador = RandomForestClassifier(n_estimators = 40, criterion = 'entropy', random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='entropy', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=40,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinando o modelo\n",
    "classificador.fit(previsores_treinamento, classe_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testando o modelo\n",
    "previsoes = classificador.predict(previsores_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando a exatidão no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8483111566018424"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precisão do modelo\n",
    "precisao = accuracy_score(classe_teste, previsoes)\n",
    "precisao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3419,  274],\n",
       "       [ 467,  725]], dtype=int64)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão\n",
    "# diagonal principal (quantidade de acertos)\n",
    "matriz = confusion_matrix(classe_teste, previsoes)\n",
    "matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>KNN</h1>\n",
    "\n",
    "O KNN (K-Nearest Neighbor) tem o objetivo de determinar a qual grupo uma determinada amostra vai pertencer com base nas amostras vizinhas. Os exemplos de treinamento são armazenados e a previsão é feita somente quando um novo registro precisa ser classificado. Diferente dos outros algoritmos, ele não constrói um modelo, apenas faz o cálculo da distância."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo e treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o algoritmo\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classificador.fit(previsores_treinamento, classe_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testando\n",
    "previsoes = classificador.predict(previsores_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando a exatidão "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8219037871033776"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precisão \n",
    "precisao = accuracy_score(classe_teste, previsoes)\n",
    "precisao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3331,  362],\n",
       "       [ 508,  684]], dtype=int64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão\n",
    "# diagonal principal (quantidade de acertos)\n",
    "matriz = confusion_matrix(classe_teste, previsoes)\n",
    "matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Regressão Logística</h1>\n",
    "\n",
    "Esse algoritmo mede a relação entre a variável dependente categórica e uma ou mais variáveis independentes, estimando as probabilidades usando uma função logística. Analisa diferentes aspectos ou variáveis de um objeto para depois determinar uma classe na qual ele se encaixa melhor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo e treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o algoritmo\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo preditivo\n",
    "classificador = LogisticRegression(solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinando o modelo\n",
    "classificador.fit(previsores_treinamento, classe_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testando o modelo\n",
    "previsoes = classificador.predict(previsores_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando a exatidão no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8184237461617195"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precisão do modelo\n",
    "precisao = accuracy_score(classe_teste, previsoes)\n",
    "precisao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3464,  229],\n",
       "       [ 658,  534]], dtype=int64)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão\n",
    "# diagonal principal (quantidade de acertos)\n",
    "matriz = confusion_matrix(classe_teste, previsoes)\n",
    "matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SVM - Máquinas de Vetores de Suporte</h1>\n",
    "\n",
    "Uma máquina de vetores de suporte (SVM) desenvolve o modelo tomando as entradas de treinamento, mapeando elas no espaço multidimensional e utilizando regressão para encontrar um hiperplano (um hiperplano é uma superfície em espaço de n dimensões que o separa em duas metades de espaço) que melhor separa duas classes de entradas. Uma vez que esse modelo tenha sido treinada, ele é capaz de avaliar novas entradas em relação ao hiperplano divisor e classificá-las em uma entre duas categorias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo e treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o algoritmo\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo preditivo\n",
    "classificador = SVC(kernel = 'linear', random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=-1, probability=False, random_state=1, shrinking=True, tol=0.001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinando o modelo\n",
    "classificador.fit(previsores_treinamento, classe_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testando o modelo\n",
    "previsoes = classificador.predict(previsores_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando a exatidão no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.813510747185261"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precisão do modelo\n",
    "precisao = accuracy_score(classe_teste, previsoes)\n",
    "precisao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3598,   95],\n",
       "       [ 816,  376]], dtype=int64)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão\n",
    "# diagonal principal (quantidade de acertos)\n",
    "matriz = confusion_matrix(classe_teste, previsoes)\n",
    "matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Redes Neurais Artificiais</h1>\n",
    "\n",
    "Redes Neurais Artificiais são técnicas computacionais que apresentam um modelo matemático inspirado na estrutura neural de organismos inteligentes e que adquirem conhecimento através da experiência. As redes neurais são compostas por várias unidades de processamento. Mesmo sendo usadas para resolverem problemas complexos, será utilizado como um exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neurais com sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo e treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando o algoritmo\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo preditivo\n",
    "classificador = MLPClassifier(verbose=True, max_iter=1000, tol= 0.000010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.42422199\n",
      "Iteration 2, loss = 0.35391352\n",
      "Iteration 3, loss = 0.33337361\n",
      "Iteration 4, loss = 0.32615847\n",
      "Iteration 5, loss = 0.32334609\n",
      "Iteration 6, loss = 0.32199615\n",
      "Iteration 7, loss = 0.32069130\n",
      "Iteration 8, loss = 0.31987058\n",
      "Iteration 9, loss = 0.31921785\n",
      "Iteration 10, loss = 0.31855495\n",
      "Iteration 11, loss = 0.31829660\n",
      "Iteration 12, loss = 0.31744305\n",
      "Iteration 13, loss = 0.31682105\n",
      "Iteration 14, loss = 0.31642574\n",
      "Iteration 15, loss = 0.31595524\n",
      "Iteration 16, loss = 0.31551810\n",
      "Iteration 17, loss = 0.31505792\n",
      "Iteration 18, loss = 0.31467126\n",
      "Iteration 19, loss = 0.31452719\n",
      "Iteration 20, loss = 0.31366123\n",
      "Iteration 21, loss = 0.31346877\n",
      "Iteration 22, loss = 0.31309825\n",
      "Iteration 23, loss = 0.31256578\n",
      "Iteration 24, loss = 0.31218147\n",
      "Iteration 25, loss = 0.31199080\n",
      "Iteration 26, loss = 0.31146256\n",
      "Iteration 27, loss = 0.31125270\n",
      "Iteration 28, loss = 0.31060299\n",
      "Iteration 29, loss = 0.31008520\n",
      "Iteration 30, loss = 0.31017551\n",
      "Iteration 31, loss = 0.30921991\n",
      "Iteration 32, loss = 0.30879183\n",
      "Iteration 33, loss = 0.30886960\n",
      "Iteration 34, loss = 0.30830793\n",
      "Iteration 35, loss = 0.30861643\n",
      "Iteration 36, loss = 0.30770207\n",
      "Iteration 37, loss = 0.30718570\n",
      "Iteration 38, loss = 0.30730303\n",
      "Iteration 39, loss = 0.30667900\n",
      "Iteration 40, loss = 0.30661809\n",
      "Iteration 41, loss = 0.30573955\n",
      "Iteration 42, loss = 0.30589770\n",
      "Iteration 43, loss = 0.30540364\n",
      "Iteration 44, loss = 0.30544278\n",
      "Iteration 45, loss = 0.30488921\n",
      "Iteration 46, loss = 0.30453127\n",
      "Iteration 47, loss = 0.30444233\n",
      "Iteration 48, loss = 0.30401475\n",
      "Iteration 49, loss = 0.30387430\n",
      "Iteration 50, loss = 0.30357057\n",
      "Iteration 51, loss = 0.30314563\n",
      "Iteration 52, loss = 0.30273228\n",
      "Iteration 53, loss = 0.30269984\n",
      "Iteration 54, loss = 0.30288343\n",
      "Iteration 55, loss = 0.30259341\n",
      "Iteration 56, loss = 0.30242347\n",
      "Iteration 57, loss = 0.30184938\n",
      "Iteration 58, loss = 0.30180006\n",
      "Iteration 59, loss = 0.30137459\n",
      "Iteration 60, loss = 0.30101445\n",
      "Iteration 61, loss = 0.30060378\n",
      "Iteration 62, loss = 0.30041502\n",
      "Iteration 63, loss = 0.30032942\n",
      "Iteration 64, loss = 0.30013682\n",
      "Iteration 65, loss = 0.30004863\n",
      "Iteration 66, loss = 0.30000672\n",
      "Iteration 67, loss = 0.29938483\n",
      "Iteration 68, loss = 0.29932648\n",
      "Iteration 69, loss = 0.29939811\n",
      "Iteration 70, loss = 0.29872070\n",
      "Iteration 71, loss = 0.29908740\n",
      "Iteration 72, loss = 0.29891318\n",
      "Iteration 73, loss = 0.29834542\n",
      "Iteration 74, loss = 0.29805635\n",
      "Iteration 75, loss = 0.29821696\n",
      "Iteration 76, loss = 0.29758354\n",
      "Iteration 77, loss = 0.29730064\n",
      "Iteration 78, loss = 0.29734472\n",
      "Iteration 79, loss = 0.29693314\n",
      "Iteration 80, loss = 0.29702903\n",
      "Iteration 81, loss = 0.29684157\n",
      "Iteration 82, loss = 0.29682312\n",
      "Iteration 83, loss = 0.29646520\n",
      "Iteration 84, loss = 0.29636513\n",
      "Iteration 85, loss = 0.29592860\n",
      "Iteration 86, loss = 0.29604640\n",
      "Iteration 87, loss = 0.29665790\n",
      "Iteration 88, loss = 0.29541304\n",
      "Iteration 89, loss = 0.29546093\n",
      "Iteration 90, loss = 0.29520223\n",
      "Iteration 91, loss = 0.29481931\n",
      "Iteration 92, loss = 0.29503251\n",
      "Iteration 93, loss = 0.29511898\n",
      "Iteration 94, loss = 0.29460237\n",
      "Iteration 95, loss = 0.29451502\n",
      "Iteration 96, loss = 0.29439677\n",
      "Iteration 97, loss = 0.29427148\n",
      "Iteration 98, loss = 0.29409558\n",
      "Iteration 99, loss = 0.29387084\n",
      "Iteration 100, loss = 0.29359669\n",
      "Iteration 101, loss = 0.29357482\n",
      "Iteration 102, loss = 0.29281336\n",
      "Iteration 103, loss = 0.29289155\n",
      "Iteration 104, loss = 0.29339200\n",
      "Iteration 105, loss = 0.29314475\n",
      "Iteration 106, loss = 0.29287151\n",
      "Iteration 107, loss = 0.29250593\n",
      "Iteration 108, loss = 0.29208696\n",
      "Iteration 109, loss = 0.29247126\n",
      "Iteration 110, loss = 0.29222999\n",
      "Iteration 111, loss = 0.29230175\n",
      "Iteration 112, loss = 0.29204690\n",
      "Iteration 113, loss = 0.29195866\n",
      "Iteration 114, loss = 0.29172439\n",
      "Iteration 115, loss = 0.29147221\n",
      "Iteration 116, loss = 0.29144257\n",
      "Iteration 117, loss = 0.29085679\n",
      "Iteration 118, loss = 0.29132316\n",
      "Iteration 119, loss = 0.29090770\n",
      "Iteration 120, loss = 0.29136606\n",
      "Iteration 121, loss = 0.29148928\n",
      "Iteration 122, loss = 0.29078262\n",
      "Iteration 123, loss = 0.29074859\n",
      "Iteration 124, loss = 0.29017500\n",
      "Iteration 125, loss = 0.29059140\n",
      "Iteration 126, loss = 0.29012665\n",
      "Iteration 127, loss = 0.29027683\n",
      "Iteration 128, loss = 0.28978830\n",
      "Iteration 129, loss = 0.28988398\n",
      "Iteration 130, loss = 0.28976367\n",
      "Iteration 131, loss = 0.28913964\n",
      "Iteration 132, loss = 0.28910632\n",
      "Iteration 133, loss = 0.28903187\n",
      "Iteration 134, loss = 0.28954512\n",
      "Iteration 135, loss = 0.28920082\n",
      "Iteration 136, loss = 0.28930271\n",
      "Iteration 137, loss = 0.28894555\n",
      "Iteration 138, loss = 0.28854087\n",
      "Iteration 139, loss = 0.28867759\n",
      "Iteration 140, loss = 0.28812511\n",
      "Iteration 141, loss = 0.28881559\n",
      "Iteration 142, loss = 0.28836589\n",
      "Iteration 143, loss = 0.28846434\n",
      "Iteration 144, loss = 0.28836970\n",
      "Iteration 145, loss = 0.28799543\n",
      "Iteration 146, loss = 0.28838521\n",
      "Iteration 147, loss = 0.28828502\n",
      "Iteration 148, loss = 0.28837902\n",
      "Iteration 149, loss = 0.28776573\n",
      "Iteration 150, loss = 0.28766483\n",
      "Iteration 151, loss = 0.28717624\n",
      "Iteration 152, loss = 0.28740310\n",
      "Iteration 153, loss = 0.28755733\n",
      "Iteration 154, loss = 0.28775337\n",
      "Iteration 155, loss = 0.28666025\n",
      "Iteration 156, loss = 0.28681950\n",
      "Iteration 157, loss = 0.28717494\n",
      "Iteration 158, loss = 0.28716228\n",
      "Iteration 159, loss = 0.28699813\n",
      "Iteration 160, loss = 0.28662963\n",
      "Iteration 161, loss = 0.28688194\n",
      "Iteration 162, loss = 0.28652391\n",
      "Iteration 163, loss = 0.28658065\n",
      "Iteration 164, loss = 0.28646208\n",
      "Iteration 165, loss = 0.28618246\n",
      "Iteration 166, loss = 0.28592460\n",
      "Iteration 167, loss = 0.28652458\n",
      "Iteration 168, loss = 0.28617278\n",
      "Iteration 169, loss = 0.28565235\n",
      "Iteration 170, loss = 0.28604118\n",
      "Iteration 171, loss = 0.28580710\n",
      "Iteration 172, loss = 0.28558694\n",
      "Iteration 173, loss = 0.28593511\n",
      "Iteration 174, loss = 0.28566802\n",
      "Iteration 175, loss = 0.28532070\n",
      "Iteration 176, loss = 0.28577886\n",
      "Iteration 177, loss = 0.28539635\n",
      "Iteration 178, loss = 0.28555263\n",
      "Iteration 179, loss = 0.28512463\n",
      "Iteration 180, loss = 0.28494800\n",
      "Iteration 181, loss = 0.28517662\n",
      "Iteration 182, loss = 0.28523799\n",
      "Iteration 183, loss = 0.28529478\n",
      "Iteration 184, loss = 0.28468069\n",
      "Iteration 185, loss = 0.28470701\n",
      "Iteration 186, loss = 0.28437010\n",
      "Iteration 187, loss = 0.28495478\n",
      "Iteration 188, loss = 0.28453424\n",
      "Iteration 189, loss = 0.28456532\n",
      "Iteration 190, loss = 0.28459204\n",
      "Iteration 191, loss = 0.28376026\n",
      "Iteration 192, loss = 0.28397495\n",
      "Iteration 193, loss = 0.28377595\n",
      "Iteration 194, loss = 0.28402056\n",
      "Iteration 195, loss = 0.28467517\n",
      "Iteration 196, loss = 0.28378469\n",
      "Iteration 197, loss = 0.28396037\n",
      "Iteration 198, loss = 0.28374986\n",
      "Iteration 199, loss = 0.28395335\n",
      "Iteration 200, loss = 0.28410777\n",
      "Iteration 201, loss = 0.28327932\n",
      "Iteration 202, loss = 0.28337887\n",
      "Iteration 203, loss = 0.28321340\n",
      "Iteration 204, loss = 0.28376827\n",
      "Iteration 205, loss = 0.28352796\n",
      "Iteration 206, loss = 0.28309772\n",
      "Iteration 207, loss = 0.28277057\n",
      "Iteration 208, loss = 0.28320589\n",
      "Iteration 209, loss = 0.28278494\n",
      "Iteration 210, loss = 0.28320018\n",
      "Iteration 211, loss = 0.28298383\n",
      "Iteration 212, loss = 0.28266993\n",
      "Iteration 213, loss = 0.28306684\n",
      "Iteration 214, loss = 0.28273483\n",
      "Iteration 215, loss = 0.28262535\n",
      "Iteration 216, loss = 0.28288094\n",
      "Iteration 217, loss = 0.28247778\n",
      "Iteration 218, loss = 0.28251865\n",
      "Iteration 219, loss = 0.28183686\n",
      "Iteration 220, loss = 0.28251455\n",
      "Iteration 221, loss = 0.28247757\n",
      "Iteration 222, loss = 0.28237981\n",
      "Iteration 223, loss = 0.28196153\n",
      "Iteration 224, loss = 0.28161933\n",
      "Iteration 225, loss = 0.28214559\n",
      "Iteration 226, loss = 0.28175905\n",
      "Iteration 227, loss = 0.28155720\n",
      "Iteration 228, loss = 0.28163344\n",
      "Iteration 229, loss = 0.28217982\n",
      "Iteration 230, loss = 0.28137880\n",
      "Iteration 231, loss = 0.28206632\n",
      "Iteration 232, loss = 0.28147832\n",
      "Iteration 233, loss = 0.28107595\n",
      "Iteration 234, loss = 0.28125647\n",
      "Iteration 235, loss = 0.28110586\n",
      "Iteration 236, loss = 0.28104818\n",
      "Iteration 237, loss = 0.28117789\n",
      "Iteration 238, loss = 0.28068210\n",
      "Iteration 239, loss = 0.28096305\n",
      "Iteration 240, loss = 0.28142070\n",
      "Iteration 241, loss = 0.28068866\n",
      "Iteration 242, loss = 0.28114692\n",
      "Iteration 243, loss = 0.28062578\n",
      "Iteration 244, loss = 0.28149575\n",
      "Iteration 245, loss = 0.28102588\n",
      "Iteration 246, loss = 0.28124001\n",
      "Iteration 247, loss = 0.28059047\n",
      "Iteration 248, loss = 0.28073606\n",
      "Iteration 249, loss = 0.28001940\n",
      "Iteration 250, loss = 0.28030909\n",
      "Iteration 251, loss = 0.28038448\n",
      "Iteration 252, loss = 0.28064804\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 253, loss = 0.28027126\n",
      "Iteration 254, loss = 0.28015698\n",
      "Iteration 255, loss = 0.28053309\n",
      "Iteration 256, loss = 0.28002856\n",
      "Iteration 257, loss = 0.28033172\n",
      "Iteration 258, loss = 0.28006230\n",
      "Iteration 259, loss = 0.28097743\n",
      "Iteration 260, loss = 0.27964005\n",
      "Iteration 261, loss = 0.27995994\n",
      "Iteration 262, loss = 0.27953421\n",
      "Iteration 263, loss = 0.27978835\n",
      "Iteration 264, loss = 0.27919320\n",
      "Iteration 265, loss = 0.27938522\n",
      "Iteration 266, loss = 0.27973609\n",
      "Iteration 267, loss = 0.27920087\n",
      "Iteration 268, loss = 0.27978675\n",
      "Iteration 269, loss = 0.28000207\n",
      "Iteration 270, loss = 0.27908397\n",
      "Iteration 271, loss = 0.27875546\n",
      "Iteration 272, loss = 0.27908424\n",
      "Iteration 273, loss = 0.27909790\n",
      "Iteration 274, loss = 0.27937269\n",
      "Iteration 275, loss = 0.27912809\n",
      "Iteration 276, loss = 0.27883464\n",
      "Iteration 277, loss = 0.27875407\n",
      "Iteration 278, loss = 0.27858891\n",
      "Iteration 279, loss = 0.27843493\n",
      "Iteration 280, loss = 0.27896489\n",
      "Iteration 281, loss = 0.27805010\n",
      "Iteration 282, loss = 0.27863987\n",
      "Iteration 283, loss = 0.27865268\n",
      "Iteration 284, loss = 0.27870396\n",
      "Iteration 285, loss = 0.27856599\n",
      "Iteration 286, loss = 0.27804491\n",
      "Iteration 287, loss = 0.27863352\n",
      "Iteration 288, loss = 0.27836484\n",
      "Iteration 289, loss = 0.27829657\n",
      "Iteration 290, loss = 0.27807414\n",
      "Iteration 291, loss = 0.27834184\n",
      "Iteration 292, loss = 0.27783918\n",
      "Iteration 293, loss = 0.27812224\n",
      "Iteration 294, loss = 0.27781884\n",
      "Iteration 295, loss = 0.27796883\n",
      "Iteration 296, loss = 0.27827918\n",
      "Iteration 297, loss = 0.27774384\n",
      "Iteration 298, loss = 0.27763122\n",
      "Iteration 299, loss = 0.27855451\n",
      "Iteration 300, loss = 0.27784286\n",
      "Iteration 301, loss = 0.27784610\n",
      "Iteration 302, loss = 0.27842981\n",
      "Iteration 303, loss = 0.27756473\n",
      "Iteration 304, loss = 0.27789553\n",
      "Iteration 305, loss = 0.27743239\n",
      "Iteration 306, loss = 0.27664703\n",
      "Iteration 307, loss = 0.27730019\n",
      "Iteration 308, loss = 0.27758244\n",
      "Iteration 309, loss = 0.27697600\n",
      "Iteration 310, loss = 0.27726224\n",
      "Iteration 311, loss = 0.27646091\n",
      "Iteration 312, loss = 0.27729080\n",
      "Iteration 313, loss = 0.27718419\n",
      "Iteration 314, loss = 0.27720493\n",
      "Iteration 315, loss = 0.27678705\n",
      "Iteration 316, loss = 0.27699268\n",
      "Iteration 317, loss = 0.27676744\n",
      "Iteration 318, loss = 0.27681884\n",
      "Iteration 319, loss = 0.27715543\n",
      "Iteration 320, loss = 0.27711207\n",
      "Iteration 321, loss = 0.27753972\n",
      "Iteration 322, loss = 0.27676871\n",
      "Training loss did not improve more than tol=0.000010 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_fun=15000, max_iter=1000,\n",
       "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
       "              power_t=0.5, random_state=None, shuffle=True, solver='adam',\n",
       "              tol=1e-05, validation_fraction=0.1, verbose=True,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinando o modelo\n",
    "classificador.fit(previsores_treinamento, classe_treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testando o modelo\n",
    "previsoes = classificador.predict(previsores_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando a exatidão no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8417604912998976"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precisão do modelo\n",
    "precisao = accuracy_score(classe_teste, previsoes)\n",
    "precisao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3414,  279],\n",
       "       [ 494,  698]], dtype=int64)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão\n",
    "# diagonal principal (quantidade de acertos)\n",
    "matriz = confusion_matrix(classe_teste, previsoes)\n",
    "matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neurais com Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construindo e treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando o modelo preditivo\n",
    "classificador = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação das camadas ocultas e de saída\n",
    "classificador.add(Dense(units = 8, activation = 'relu', input_dim = 14))\n",
    "classificador.add(Dense(units = 8, activation = 'relu'))\n",
    "classificador.add(Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilando a rede neural\n",
    "classificador.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3941 - accuracy: 0.8228\n",
      "Epoch 2/100\n",
      "27676/27676 [==============================] - 2s 66us/step - loss: 0.3355 - accuracy: 0.8413\n",
      "Epoch 3/100\n",
      "27676/27676 [==============================] - 2s 66us/step - loss: 0.3288 - accuracy: 0.8453\n",
      "Epoch 4/100\n",
      "27676/27676 [==============================] - 2s 66us/step - loss: 0.3260 - accuracy: 0.8465\n",
      "Epoch 5/100\n",
      "27676/27676 [==============================] - 2s 66us/step - loss: 0.3241 - accuracy: 0.8467\n",
      "Epoch 6/100\n",
      "27676/27676 [==============================] - 2s 66us/step - loss: 0.3224 - accuracy: 0.8495\n",
      "Epoch 7/100\n",
      "27676/27676 [==============================] - 2s 68us/step - loss: 0.3218 - accuracy: 0.8497\n",
      "Epoch 8/100\n",
      "27676/27676 [==============================] - 2s 66us/step - loss: 0.3209 - accuracy: 0.8503\n",
      "Epoch 9/100\n",
      "27676/27676 [==============================] - 2s 67us/step - loss: 0.3202 - accuracy: 0.8504\n",
      "Epoch 10/100\n",
      "27676/27676 [==============================] - 2s 64us/step - loss: 0.3193 - accuracy: 0.8501\n",
      "Epoch 11/100\n",
      "27676/27676 [==============================] - 2s 63us/step - loss: 0.3191 - accuracy: 0.8511\n",
      "Epoch 12/100\n",
      "27676/27676 [==============================] - 2s 65us/step - loss: 0.3181 - accuracy: 0.8517\n",
      "Epoch 13/100\n",
      "27676/27676 [==============================] - 2s 64us/step - loss: 0.3181 - accuracy: 0.8517\n",
      "Epoch 14/100\n",
      "27676/27676 [==============================] - 2s 63us/step - loss: 0.3176 - accuracy: 0.8514\n",
      "Epoch 15/100\n",
      "27676/27676 [==============================] - 2s 66us/step - loss: 0.3171 - accuracy: 0.8519\n",
      "Epoch 16/100\n",
      "27676/27676 [==============================] - 2s 64us/step - loss: 0.3171 - accuracy: 0.8511\n",
      "Epoch 17/100\n",
      "27676/27676 [==============================] - 2s 67us/step - loss: 0.3171 - accuracy: 0.8513\n",
      "Epoch 18/100\n",
      "27676/27676 [==============================] - 2s 64us/step - loss: 0.3169 - accuracy: 0.8524\n",
      "Epoch 19/100\n",
      "27676/27676 [==============================] - 2s 68us/step - loss: 0.3161 - accuracy: 0.8521\n",
      "Epoch 20/100\n",
      "27676/27676 [==============================] - 2s 67us/step - loss: 0.3164 - accuracy: 0.8530\n",
      "Epoch 21/100\n",
      "27676/27676 [==============================] - 2s 66us/step - loss: 0.3165 - accuracy: 0.8527\n",
      "Epoch 22/100\n",
      "27676/27676 [==============================] - 2s 68us/step - loss: 0.3163 - accuracy: 0.8517\n",
      "Epoch 23/100\n",
      "27676/27676 [==============================] - 2s 67us/step - loss: 0.3163 - accuracy: 0.8529\n",
      "Epoch 24/100\n",
      "27676/27676 [==============================] - 2s 66us/step - loss: 0.3160 - accuracy: 0.8528\n",
      "Epoch 25/100\n",
      "27676/27676 [==============================] - 2s 65us/step - loss: 0.3158 - accuracy: 0.8531\n",
      "Epoch 26/100\n",
      "27676/27676 [==============================] - 2s 65us/step - loss: 0.3156 - accuracy: 0.8532\n",
      "Epoch 27/100\n",
      "27676/27676 [==============================] - 2s 66us/step - loss: 0.3155 - accuracy: 0.8506\n",
      "Epoch 28/100\n",
      "27676/27676 [==============================] - 2s 65us/step - loss: 0.3156 - accuracy: 0.8530\n",
      "Epoch 29/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3152 - accuracy: 0.8519\n",
      "Epoch 30/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3151 - accuracy: 0.8519\n",
      "Epoch 31/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3150 - accuracy: 0.8528\n",
      "Epoch 32/100\n",
      "27676/27676 [==============================] - 2s 68us/step - loss: 0.3151 - accuracy: 0.8527\n",
      "Epoch 33/100\n",
      "27676/27676 [==============================] - 2s 68us/step - loss: 0.3151 - accuracy: 0.8516\n",
      "Epoch 34/100\n",
      "27676/27676 [==============================] - 2s 68us/step - loss: 0.3149 - accuracy: 0.8529\n",
      "Epoch 35/100\n",
      "27676/27676 [==============================] - 2s 68us/step - loss: 0.3148 - accuracy: 0.8527\n",
      "Epoch 36/100\n",
      "27676/27676 [==============================] - 2s 68us/step - loss: 0.3146 - accuracy: 0.8525\n",
      "Epoch 37/100\n",
      "27676/27676 [==============================] - 2s 68us/step - loss: 0.3145 - accuracy: 0.8525\n",
      "Epoch 38/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3147 - accuracy: 0.8522\n",
      "Epoch 39/100\n",
      "27676/27676 [==============================] - 2s 68us/step - loss: 0.3145 - accuracy: 0.8524\n",
      "Epoch 40/100\n",
      "27676/27676 [==============================] - 2s 68us/step - loss: 0.3148 - accuracy: 0.8529\n",
      "Epoch 41/100\n",
      "27676/27676 [==============================] - 2s 65us/step - loss: 0.3145 - accuracy: 0.8527\n",
      "Epoch 42/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3147 - accuracy: 0.8532\n",
      "Epoch 43/100\n",
      "27676/27676 [==============================] - 2s 71us/step - loss: 0.3144 - accuracy: 0.8524\n",
      "Epoch 44/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3143 - accuracy: 0.8544\n",
      "Epoch 45/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3143 - accuracy: 0.8531\n",
      "Epoch 46/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3143 - accuracy: 0.8534\n",
      "Epoch 47/100\n",
      "27676/27676 [==============================] - 2s 68us/step - loss: 0.3142 - accuracy: 0.8525\n",
      "Epoch 48/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3143 - accuracy: 0.8528\n",
      "Epoch 49/100\n",
      "27676/27676 [==============================] - 2s 68us/step - loss: 0.3145 - accuracy: 0.8532\n",
      "Epoch 50/100\n",
      "27676/27676 [==============================] - 2s 68us/step - loss: 0.3138 - accuracy: 0.8537\n",
      "Epoch 51/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3142 - accuracy: 0.8534\n",
      "Epoch 52/100\n",
      "27676/27676 [==============================] - 2s 70us/step - loss: 0.3140 - accuracy: 0.8529\n",
      "Epoch 53/100\n",
      "27676/27676 [==============================] - 2s 66us/step - loss: 0.3139 - accuracy: 0.8526\n",
      "Epoch 54/100\n",
      "27676/27676 [==============================] - 2s 65us/step - loss: 0.3142 - accuracy: 0.8529\n",
      "Epoch 55/100\n",
      "27676/27676 [==============================] - 2s 65us/step - loss: 0.3137 - accuracy: 0.8530\n",
      "Epoch 56/100\n",
      "27676/27676 [==============================] - 2s 70us/step - loss: 0.3141 - accuracy: 0.8527\n",
      "Epoch 57/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3139 - accuracy: 0.8520\n",
      "Epoch 58/100\n",
      "27676/27676 [==============================] - 2s 65us/step - loss: 0.3135 - accuracy: 0.8527\n",
      "Epoch 59/100\n",
      "27676/27676 [==============================] - 2s 65us/step - loss: 0.3139 - accuracy: 0.8539\n",
      "Epoch 60/100\n",
      "27676/27676 [==============================] - 2s 64us/step - loss: 0.3140 - accuracy: 0.8530\n",
      "Epoch 61/100\n",
      "27676/27676 [==============================] - 2s 64us/step - loss: 0.3138 - accuracy: 0.8534\n",
      "Epoch 62/100\n",
      "27676/27676 [==============================] - 2s 67us/step - loss: 0.3139 - accuracy: 0.8530\n",
      "Epoch 63/100\n",
      "27676/27676 [==============================] - 2s 68us/step - loss: 0.3138 - accuracy: 0.8537\n",
      "Epoch 64/100\n",
      "27676/27676 [==============================] - 2s 68us/step - loss: 0.3137 - accuracy: 0.8526\n",
      "Epoch 65/100\n",
      "27676/27676 [==============================] - 2s 68us/step - loss: 0.3133 - accuracy: 0.8536\n",
      "Epoch 66/100\n",
      "27676/27676 [==============================] - 2s 68us/step - loss: 0.3137 - accuracy: 0.8538\n",
      "Epoch 67/100\n",
      "27676/27676 [==============================] - 2s 68us/step - loss: 0.3134 - accuracy: 0.8528\n",
      "Epoch 68/100\n",
      "27676/27676 [==============================] - 2s 72us/step - loss: 0.3137 - accuracy: 0.8523\n",
      "Epoch 69/100\n",
      "27676/27676 [==============================] - 2s 70us/step - loss: 0.3135 - accuracy: 0.8524\n",
      "Epoch 70/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3134 - accuracy: 0.8532\n",
      "Epoch 71/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3134 - accuracy: 0.8532\n",
      "Epoch 72/100\n",
      "27676/27676 [==============================] - 2s 67us/step - loss: 0.3131 - accuracy: 0.8532\n",
      "Epoch 73/100\n",
      "27676/27676 [==============================] - 2s 65us/step - loss: 0.3134 - accuracy: 0.8538\n",
      "Epoch 74/100\n",
      "27676/27676 [==============================] - 2s 67us/step - loss: 0.3132 - accuracy: 0.8554\n",
      "Epoch 75/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3130 - accuracy: 0.8535\n",
      "Epoch 76/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3132 - accuracy: 0.8526\n",
      "Epoch 77/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3128 - accuracy: 0.8534\n",
      "Epoch 78/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3128 - accuracy: 0.8550\n",
      "Epoch 79/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3130 - accuracy: 0.8534\n",
      "Epoch 80/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3127 - accuracy: 0.8538\n",
      "Epoch 81/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3128 - accuracy: 0.8530\n",
      "Epoch 82/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3130 - accuracy: 0.8537\n",
      "Epoch 83/100\n",
      "27676/27676 [==============================] - 2s 70us/step - loss: 0.3124 - accuracy: 0.8543\n",
      "Epoch 84/100\n",
      "27676/27676 [==============================] - 2s 72us/step - loss: 0.3129 - accuracy: 0.8531\n",
      "Epoch 85/100\n",
      "27676/27676 [==============================] - 2s 69us/step - loss: 0.3125 - accuracy: 0.8544\n",
      "Epoch 86/100\n",
      "27676/27676 [==============================] - 2s 70us/step - loss: 0.3124 - accuracy: 0.8545\n",
      "Epoch 87/100\n",
      "27676/27676 [==============================] - 2s 70us/step - loss: 0.3127 - accuracy: 0.8542\n",
      "Epoch 88/100\n",
      "27676/27676 [==============================] - 2s 71us/step - loss: 0.3122 - accuracy: 0.8546\n",
      "Epoch 89/100\n",
      "27676/27676 [==============================] - 2s 71us/step - loss: 0.3124 - accuracy: 0.8536\n",
      "Epoch 90/100\n",
      "27676/27676 [==============================] - 2s 66us/step - loss: 0.3123 - accuracy: 0.8535\n",
      "Epoch 91/100\n",
      "27676/27676 [==============================] - 2s 71us/step - loss: 0.3121 - accuracy: 0.8547\n",
      "Epoch 92/100\n",
      "27676/27676 [==============================] - 2s 67us/step - loss: 0.3124 - accuracy: 0.8540\n",
      "Epoch 93/100\n",
      "27676/27676 [==============================] - 2s 70us/step - loss: 0.3123 - accuracy: 0.8546\n",
      "Epoch 94/100\n",
      "27676/27676 [==============================] - 2s 71us/step - loss: 0.3122 - accuracy: 0.8546\n",
      "Epoch 95/100\n",
      "27676/27676 [==============================] - 2s 70us/step - loss: 0.3121 - accuracy: 0.8547\n",
      "Epoch 96/100\n",
      "27676/27676 [==============================] - 2s 71us/step - loss: 0.3119 - accuracy: 0.8548\n",
      "Epoch 97/100\n",
      "27676/27676 [==============================] - 2s 72us/step - loss: 0.3121 - accuracy: 0.8539\n",
      "Epoch 98/100\n",
      "27676/27676 [==============================] - 2s 71us/step - loss: 0.3117 - accuracy: 0.8557\n",
      "Epoch 99/100\n",
      "27676/27676 [==============================] - 2s 71us/step - loss: 0.3121 - accuracy: 0.8552\n",
      "Epoch 100/100\n",
      "27676/27676 [==============================] - 2s 73us/step - loss: 0.3121 - accuracy: 0.8550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x27e230368c8>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Treinando o modelo\n",
    "classificador.fit(previsores_treinamento, classe_treinamento, batch_size = 10, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testando o modelo\n",
    "previsoes = classificador.predict(previsores_teste)\n",
    "previsoes = (previsoes > 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando a exatidão no modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.847697031729785"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# precisão do modelo\n",
    "precisao = accuracy_score(classe_teste, previsoes)\n",
    "precisao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3406,  287],\n",
       "       [ 457,  735]], dtype=int64)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matriz de confusão\n",
    "# diagonal principal (quantidade de acertos)\n",
    "matriz = confusion_matrix(classe_teste, previsoes)\n",
    "matriz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Conclusão</h1>\n",
    "\n",
    "Realizando apenas um teste podemos observar que os Algoritmos de Redes Neurais Artificiais e Random Forest tiveram um maior percentual de acerto nessa base de dados. Isso não significa que esses algoritmos sejam os melhores a serem utilizados para prever a renda anual por pessoa dessa base de dados. Para uma melhor compreensão desse resultado, deve ser feito mais testes a fim de comprovar a eficácia desses algoritmos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
